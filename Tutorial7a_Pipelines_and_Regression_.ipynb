{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Plant Machine Learning Pipeline Application\n",
    "This notebook is an end-to-end exercise of performing Extract-Transform-Load and\n",
    "Exploratory Data Analysis on a real-world dataset, and then applying several\n",
    "different machine learning algorithms to solve a supervised regression problem\n",
    "on the dataset.\n",
    "\n",
    "**This notebook covers:**\n",
    "\n",
    "* *Part 1: Business Understanding*\n",
    "* *Part 2: Load Your Data*\n",
    "* *Part 3: Explore Your Data*\n",
    "* *Part 4: Visualize Your Data*\n",
    "* *Part 5: Data Preparation*\n",
    "\n",
    "\n",
    "*Our goal is to accurately predict power output given a set of environmental\n",
    "readings from various sensors in a natural gas-fired power generation plant.*\n",
    "\n",
    "\n",
    "**Background**\n",
    "\n",
    "Power generation is a complex process, and understanding and predicting power\n",
    "output is an important element in managing a plant and its connection to the\n",
    "power grid. The operators of a regional power grid create predictions of power\n",
    "demand based on historical information and environmental factors (e.g.,\n",
    "temperature). They then compare the predictions against available resources\n",
    "(e.g., coal, natural gas, nuclear, solar, wind, hydro power plants). Power\n",
    "generation technologies such as solar and wind are highly dependent on\n",
    "environmental conditions, and all generation technologies are subject to planned\n",
    "and unplanned maintenance.\n",
    "\n",
    "Here is an real-world example of predicted demand (on two time scales), actual\n",
    "demand, and available resources from the California power grid:\n",
    "<http://www.caiso.com/Pages/TodaysOutlook.aspx>\n",
    "\n",
    "![](http://content.caiso.com/outlook/SP/ems_small.gif)\n",
    "\n",
    "The challenge for a power grid operator is how to handle a shortfall in\n",
    "available resources versus actual demand. There are three solutions to  a power\n",
    "shortfall: build more base load power plants (this process can take many years\n",
    "to decades of planning and construction), buy and import power from other\n",
    "regional power grids (this choice can be very expensive and is limited by the\n",
    "power transmission interconnects between grids and the excess power available\n",
    "from other grids), or turn on small [Peaker or Peaking Power\n",
    "Plants](https://en.wikipedia.org/wiki/Peaking_power_plant). Because grid\n",
    "operators need to respond quickly to a power shortfall to avoid a power outage,\n",
    "grid operators rely on a combination of the last two choices. In this exercise, we'll focus on the last choice.\n",
    "\n",
    "**The Business Problem**\n",
    "\n",
    "Because they supply power only occasionally, the power supplied by a peaker\n",
    "power plant commands a much higher price per kilowatt hour than power from a\n",
    "power grid's base power plants. A peaker plant may operate many hours a day, or\n",
    "it may operate only a few hours per year, depending on the condition of the\n",
    "region's electrical grid. Because of the cost of building an efficient power\n",
    "plant, if a peaker plant is only going to be run for a short or highly variable\n",
    "time it does not make economic sense to make it as efficient as a base load\n",
    "power plant. In addition, the equipment and fuels used in base load plants are\n",
    "often unsuitable for use in peaker plants because the fluctuating conditions\n",
    "would severely strain the equipment.\n",
    "\n",
    "The power output of a peaker power plant varies depending on environmental\n",
    "conditions, so the business problem is _predicting the power output of a peaker\n",
    "power plant as a function of the environmental conditions_ -- since this would\n",
    "enable the grid operator to make economic tradeoffs about the number of peaker\n",
    "plants to turn on (or whether to buy expensive power from another grid).\n",
    "\n",
    "Given this business problem, we need to first perform Exploratory Data Analysis\n",
    "to understand the data and then translate the business problem (predicting power\n",
    "output as a function of environmental conditions) into a Machine Learning task.\n",
    "In this instance, the ML task is regression since the label (or target) we are\n",
    "trying to predict is numeric. We will use an [Apache Spark ML\n",
    "Pipeline](https://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark-ml-package) to perform the regression.\n",
    "\n",
    "The real-world data we are using in this notebook consists of 9,568 data points,\n",
    "each with 4 environmental attributes collected from a Combined Cycle Power Plant\n",
    "over 6 years (2006-2011), and is provided by the University of California,\n",
    "Irvine at [UCI Machine Learning Repository Combined Cycle Power Plant Data\n",
    "Set](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant). You\n",
    "can find more details about the dataset on the UCI page, including the following\n",
    "background publications:\n",
    "\n",
    "* Pinar Tüfekci, [Prediction of full load electrical power output of a base load\n",
    "operated combined cycle power plant using machine learning\n",
    "methods](http://www.journals.elsevier.com/international-journal-of-electrical-\n",
    "power-and-energy-systems/), International Journal of Electrical Power & Energy\n",
    "Systems, Volume 60, September 2014, Pages 126-140, ISSN 0142-0615.\n",
    "* Heysem Kaya, Pinar Tüfekci and Fikret S. Gürgen: [Local and Global Learning\n",
    "Methods for Predicting Power of a Combined Gas & Steam\n",
    "Turbine](http://www.cmpe.boun.edu.tr/~kaya/kaya2012gasturbine.pdf), Proceedings\n",
    "of the International Conference on Emerging Trends in Computer and Electronics\n",
    "Engineering ICETCEE 2012, pp. 13-18 (Mar. 2012, Dubai).\n",
    "\n",
    "**Note**:  \n",
    "For more in-depth details always refer to the documentation for [Spark Machine Learning\n",
    "Pipeline](https://spark.apache.org/docs/latest/ml-pipeline.html).\n",
    "\n",
    "Initialize the Spark environment with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pixiedust'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e10211a39b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpixiedust\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pixiedust'"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable monitoring of Spark via the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully enabled Spark Job Progress Monitor\n"
     ]
    }
   ],
   "source": [
    "pixiedust.enableJobMonitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is a Spark Session, named `spark` that available for this notebook. Check it out  here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://127.0.0.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[10]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fcb1943a860>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: In which mode does Spark work?\n",
    "\n",
    "## Part 1: Business Understanding\n",
    "The first step in any machine learning task is to understand the business need.\n",
    "\n",
    "As described in the overview we are trying to predict power output given a set\n",
    "of readings from various sensors in a gas-fired power generation plant.\n",
    "\n",
    "The dataset contains the following hourly average ambient variables:\n",
    "\n",
    "- Temperature (`T`) in °C,\n",
    "- Ambient Pressure (`AP`) in  milibar,\n",
    "- Relative Humidity (`RH`) as a percentage\n",
    "- Exhaust Vacuum (`V`) pressure in cm Hg\n",
    "- Net hourly electrical energy output (`EP`) in MW (megawatts)\n",
    "\n",
    "The averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization.\n",
    "\n",
    "\n",
    "The problem is a regression problem since the label (or target) we are trying to predict is numeric, i.e. we want to produce a model that given as inputs `T`, `AP`, `RH` and `V` will produce estimates of `EP`.\n",
    "\n",
    "$ EP = f(T, AP, RH, V) $ \n",
    "\n",
    "A graphical representation of the model is below.\n",
    "\n",
    "![A graphical representation of the model](images/model.001.jpeg)\n",
    "\n",
    "## Part 2: Extract-Transform-Load (ETL) Your Data\n",
    "\n",
    "Now that we understand what we are trying to do, the first step is to load our\n",
    "data into a format we can query and use.  This is known as ETL or \"Extract-\n",
    "Transform-Load\".  \n",
    "\n",
    "Our data is available in the folder `../data/powerplant`, stored in 5 files named Sheet1.csv to Sheet 5.csv\n",
    "\n",
    "### Exercise 1 (a)\n",
    "\n",
    "**To Do:** Let's start by having a look on the data folder.\n",
    "\n",
    "Browse to the [folder data/powerplant](../data/powerplant) and explore the files available.\n",
    "\n",
    "What did we need to observe?\n",
    "\n",
    "From our initial exploration of the data, we can make several\n",
    "observations for the ETL process:\n",
    "\n",
    "  - The data is a set of .csv (Comma Seperated Values) files (i.e., each row of the data is separated using tabs)\n",
    "  - There is a header row, which is the name of the columns\n",
    "  - It looks like the type of the data in each column is consistent (i.e., each\n",
    "column is of type double)\n",
    "\n",
    "\n",
    "\n",
    "Now, let's use Spark to load the dataset into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerPlantDF = spark.read.csv('../data/powerplant/', header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that instead of pointing to a single file we point to folder! All data from all files are read together in a single dataframe!\n",
    "\n",
    "\n",
    "### Exercise 2 (b)\n",
    "\n",
    "Start exploring your dataframe, and verify the names and types of the data columns \n",
    "\n",
    "Check the names and types of the columns using the `dtypes` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AT', 'double'), ('V', 'double'), ('AP', 'double'), ('RH', 'double'), ('PE', 'double')]\n"
     ]
    }
   ],
   "source": [
    "print (powerPlantDF.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can examine the data using the `printSchema()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AT: double (nullable = true)\n",
      " |-- V: double (nullable = true)\n",
      " |-- AP: double (nullable = true)\n",
      " |-- RH: double (nullable = true)\n",
      " |-- PE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "powerPlantDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Explore Your Data\n",
    "\n",
    "Let's get some basic statistical summary of all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pixiedust/utils/sparkJobProgressMonitor.py\", line 47, in startSparkJobProgressMonitor\n",
      "    progressMonitor = SparkJobProgressMonitor()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pixiedust/utils/sparkJobProgressMonitor.py\", line 174, in __init__\n",
      "    self.addSparkListener()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pixiedust/utils/sparkJobProgressMonitor.py\", line 203, in addSparkListener\n",
      "    _env.getTemplate(\"sparkJobProgressMonitor/addSparkListener.scala\").render()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2131, in run_cell_magic\n",
      "    result = fn(magic_arg_s, cell)\n",
      "  File \"<decorator-gen-126>\", line 2, in scala\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pixiedust/utils/scalaBridge.py\", line 183, in scala\n",
      "    self.getLineOption(line, \"channel\"), self.getLineOption(line, \"receiver\"))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pixiedust/utils/javaBridge.py\", line 51, in __init__\n",
      "    self.captureOutput(captureOutput)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pixiedust/utils/javaBridge.py\", line 71, in captureOutput\n",
      "    pixiedustOutputSink = JavaWrapper(\"com.ibm.pixiedust.PixiedustOutputStream\").jHandle(self.outputChannel)\n",
      "TypeError: 'JavaPackage' object is not callable\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|                AT|                 V|                AP|                RH|                PE|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|             47840|             47840|             47840|             47840|             47840|\n",
      "|   mean|19.651231187290996| 54.30580372073594|1013.2590781772572| 73.30897784280918|454.36500940635506|\n",
      "| stddev| 7.452161658340004|12.707361709685806| 5.938535418520815|14.599658352081477| 17.06628146683769|\n",
      "|    min|              1.81|             25.36|            992.89|             25.56|            420.26|\n",
      "|    max|             37.11|             81.56|            1033.3|            100.16|            495.76|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "powerPlantDF.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What do you observe from the summury statistics above? Discuss in pairs. \n",
    "\n",
    "\n",
    "## Part 4: Visualize Your Data\n",
    "\n",
    "To understand our data, we will look for correlations between inputs and the\n",
    "output.  \n",
    "This can be important when choosing a model.  E.g., if features and a\n",
    "label are linearly correlated, a linear model like Linear Regression can do\n",
    "well; if the relationship is very non-linear, more complex models such as\n",
    "Decision Trees can be better. \n",
    "\n",
    "\n",
    "For the visualization, we will use Pixiedust, and the embedded `display`  function.\n",
    "\n",
    "\n",
    "### Exercise 4(a)\n",
    "\n",
    "\n",
    "Let's start with examining if there is a correlation between Temperature and Power Output. \n",
    "\n",
    "In the cell below, visualize the `powerPlantDF` dataframe. \n",
    "What we will see first, is a tabular view of the `powerPlantDF`. Note that not the whole dataset is visualized, rather 100 records only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div><style type=\"text/css\" class=\"pd_save is-viewer-good\">\n",
       "  .df-table-wrapper .panel-heading {\n",
       "    border-radius: 0;\n",
       "    padding: 0px;\n",
       "  }\n",
       "  .df-table-wrapper .panel-heading:hover {\n",
       "    border-color: #008571;\n",
       "  }\n",
       "  .df-table-wrapper .panel-title a {\n",
       "    background-color: #f9f9fb;\n",
       "    color: #333333;\n",
       "    display: block;\n",
       "    outline: none;\n",
       "    padding: 10px 15px;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .df-table-wrapper .panel-title a:hover {\n",
       "    background-color: #337ab7;\n",
       "    border-color: #2e6da4;\n",
       "    color: #ffffff;\n",
       "    display: block;\n",
       "    padding: 10px 15px;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .df-table-wrapper {\n",
       "    font-size: small;\n",
       "    font-weight: 300;\n",
       "    letter-spacing: 0.5px;\n",
       "    line-height: normal;\n",
       "    height: inherit;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  .df-table-search-count {\n",
       "    display: inline-block;\n",
       "    margin: 20px 0;\n",
       "  }\n",
       "  .df-table-container {\n",
       "    max-height: 50vh;\n",
       "    max-width: 100%;\n",
       "    overflow-x: auto;\n",
       "    position: relative;\n",
       "  }\n",
       "  .df-table-wrapper table {\n",
       "    border: 0 none #ffffff;\n",
       "    border-collapse: collapse;\n",
       "    margin: 0;\n",
       "    min-width: 100%;\n",
       "    padding: 0;\n",
       "    table-layout: fixed;\n",
       "    height: inherit;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  .df-table-wrapper tr.hidden {\n",
       "    display: none;\n",
       "  }\n",
       "  .df-table-wrapper tr:nth-child(even) {\n",
       "    background-color: #f9f9fb;\n",
       "  }\n",
       "  .df-table-wrapper tr.even {\n",
       "    background-color: #f9f9fb;\n",
       "  }\n",
       "  .df-table-wrapper tr.odd {\n",
       "    background-color: #ffffff;\n",
       "  }\n",
       "  .df-table-wrapper td + td {\n",
       "    border-left: 1px solid #e0e0e0;\n",
       "  }\n",
       "\n",
       "  .df-table-wrapper thead,\n",
       "  .fixed-header {\n",
       "    color: #337ab7;\n",
       "    font-family: monospace;\n",
       "  }\n",
       "  .df-table-wrapper tr,\n",
       "  .fixed-row {\n",
       "    border: 0 none #ffffff;\n",
       "    margin: 0;\n",
       "    padding: 0;\n",
       "  }\n",
       "  .df-table-wrapper th,\n",
       "  .df-table-wrapper td,\n",
       "  .fixed-cell {\n",
       "    border: 0 none #ffffff;\n",
       "    margin: 0;\n",
       "    min-width: 50px;\n",
       "    padding: 5px 20px 5px 10px;\n",
       "    text-align: left;\n",
       "    word-wrap: break-word;\n",
       "  }\n",
       "  .df-table-wrapper th {\n",
       "    padding-bottom: 0;\n",
       "    padding-top: 0;\n",
       "  }\n",
       "  .df-table-wrapper th div {\n",
       "    max-height: 1px;\n",
       "    visibility: hidden;\n",
       "  }\n",
       "\n",
       "  .df-schema-field {\n",
       "    margin-left: 10px;\n",
       "  }\n",
       "\n",
       "  .fixed-header-container {\n",
       "    overflow: hidden;\n",
       "    position: relative;\n",
       "  }\n",
       "  .fixed-header {\n",
       "    border-bottom: 2px solid #2e6da4;\n",
       "    display: table;\n",
       "    position: relative;\n",
       "  }\n",
       "  .fixed-row {\n",
       "    display: table-row;\n",
       "  }\n",
       "  .fixed-cell {\n",
       "    display: table-cell;\n",
       "  }\n",
       "</style><div class=\"df-table-wrapper df-table-wrapper-0f542728 panel-group pd_save is-viewer-good\">\n",
       "  <!-- dataframe schema -->\n",
       "  \n",
       "  <div class=\"panel panel-default\">\n",
       "    <div class=\"panel-heading\">\n",
       "      <h4 class=\"panel-title\" style=\"margin: 0px;\">\n",
       "        <a data-toggle=\"collapse\" href=\"#df-schema-0f542728\" data-parent=\"#df-table-wrapper-0f542728\">Schema</a>\n",
       "      </h4>\n",
       "    </div>\n",
       "    <div id=\"df-schema-0f542728\" class=\"panel-collapse collapse\">\n",
       "      <div class=\"panel-body\" style=\"font-family: monospace;\">\n",
       "        <div class=\"df-schema-type\">\n",
       "          <span>type: </span><span>struct</span>\n",
       "        </div>\n",
       "        <div class=\"df-schema-fields\">\n",
       "          <div>field:</div>\n",
       "          \n",
       "            <div class=\"df-schema-field\">{'name': 'AT', 'type': 'double', 'nullable': True, 'metadata': {}}</div>\n",
       "          \n",
       "            <div class=\"df-schema-field\">{'name': 'V', 'type': 'double', 'nullable': True, 'metadata': {}}</div>\n",
       "          \n",
       "            <div class=\"df-schema-field\">{'name': 'AP', 'type': 'double', 'nullable': True, 'metadata': {}}</div>\n",
       "          \n",
       "            <div class=\"df-schema-field\">{'name': 'RH', 'type': 'double', 'nullable': True, 'metadata': {}}</div>\n",
       "          \n",
       "            <div class=\"df-schema-field\">{'name': 'PE', 'type': 'double', 'nullable': True, 'metadata': {}}</div>\n",
       "          \n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "  </div>\n",
       "  \n",
       "  <!-- dataframe table -->\n",
       "  <div class=\"panel panel-default\">\n",
       "    \n",
       "    <div class=\"panel-heading\">\n",
       "      <h4 class=\"panel-title\" style=\"margin: 0px;\">\n",
       "        <a data-toggle=\"collapse\" href=\"#df-table-0f542728\" data-parent=\"#df-table-wrapper-0f542728\">Table</a>\n",
       "      </h4>\n",
       "    </div>\n",
       "    \n",
       "    <div id=\"df-table-0f542728\" class=\"panel-collapse collapse in\">\n",
       "      <div class=\"panel-body\">\n",
       "        \n",
       "        <input type=\"text\" class=\"df-table-search form-control input-sm\" placeholder=\"Search table\">\n",
       "        <div>\n",
       "          <span class=\"df-table-search-count\">Showing 100 of 47840</span>\n",
       "        </div>\n",
       "        <!-- fixed header for when dataframe table scrolls -->\n",
       "        <div class=\"fixed-header-container\">\n",
       "          <div class=\"fixed-header\">\n",
       "            <div class=\"fixed-row\">\n",
       "              \n",
       "              \n",
       "              <div class=\"fixed-cell\">AT</div>\n",
       "              \n",
       "              \n",
       "              \n",
       "              <div class=\"fixed-cell\">V</div>\n",
       "              \n",
       "              \n",
       "              \n",
       "              <div class=\"fixed-cell\">AP</div>\n",
       "              \n",
       "              \n",
       "              \n",
       "              <div class=\"fixed-cell\">RH</div>\n",
       "              \n",
       "              \n",
       "              \n",
       "              <div class=\"fixed-cell\">PE</div>\n",
       "              \n",
       "              \n",
       "            </div>\n",
       "          </div>\n",
       "        </div>\n",
       "        <div class=\"df-table-container\">\n",
       "          <table class=\"df-table\">\n",
       "            <thead>\n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <th><div>AT</div></th>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th><div>V</div></th>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th><div>AP</div></th>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th><div>RH</div></th>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th><div>PE</div></th>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "            </thead>\n",
       "            <tbody>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>9.44</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>40.0</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1015.62</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>81.16</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>471.32</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>23.49</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>49.3</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1003.35</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>77.96</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>442.76</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>4.99</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>39.04</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1020.45</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>78.89</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>472.52</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>18.24</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>58.46</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1017.38</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>86.92</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>449.63</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>27.49</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>63.78</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1015.43</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>47.45</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>445.66</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>13.61</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>41.16</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1020.49</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>75.09</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>462.67</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>29.75</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>73.5</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1011.13</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>67.31</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>433.63</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>27.38</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>77.24</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1008.25</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>82.49</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>435.81</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>18.28</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>60.1</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.72</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>85.79</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>452.93</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>23.74</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>62.96</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1019.65</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>63.39</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>449.48</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>7.78</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>40.8</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1026.7</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>85.61</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>488.54</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>19.72</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>46.21</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1010.54</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>77.74</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>449.33</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>23.18</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>72.99</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.01</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>90.09</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>439.12</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>18.5</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>52.08</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1006.23</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>100.09</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>451.23</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>14.39</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>42.77</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1017.36</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>83.28</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>463.65</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>29.56</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>52.84</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1006.09</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>42.17</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>436.46</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>8.4</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>38.5</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1013.67</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>69.13</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>486.5</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>25.47</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>60.75</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1007.27</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>65.91</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>438.42</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>15.23</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>44.9</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1007.75</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>81.34</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>456.07</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>12.78</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>44.6</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1013.64</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>77.56</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>468.67</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>10.16</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>41.62</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1013.15</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>94.3</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>465.05</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>9.83</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>41.17</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1019.34</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>72.29</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>478.21</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>26.72</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>56.9</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1007.12</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>58.54</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>435.16</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>9.41</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>34.69</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1027.02</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>78.91</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>480.87</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>8.51</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>40.81</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1015.54</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>83.16</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>481.02</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>11.39</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>40.27</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.04</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>73.13</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>474.93</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>28.44</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>69.4</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1003.98</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>73.51</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>433.44</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>12.74</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>41.38</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1021.92</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>56.67</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>475.63</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>24.99</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>58.79</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1016.37</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>67.16</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>439.2</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>22.1</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>65.94</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.79</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>67.57</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>443.95</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>14.38</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>44.84</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1024.59</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>81.68</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>471.6</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>10.59</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>41.46</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1016.87</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>85.7</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>480.83</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>16.22</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>41.35</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1000.96</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>79.59</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>462.21</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>17.52</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>44.05</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1008.87</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>85.67</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>455.72</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>25.35</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>72.99</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1007.65</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>84.09</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>436.29</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>15.14</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>37.85</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1010.33</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>84.3</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>468.31</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>19.78</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>54.42</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1011.74</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>89.34</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>456.84</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>28.14</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>76.86</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1000.7</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>70.17</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>434.68</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>8.07</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>41.01</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1023.26</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>97.5</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>474.09</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>21.91</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>63.76</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.85</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>76.8</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>445.04</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>7.41</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>39.16</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1015.23</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>90.66</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>486.91</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>16.14</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>44.71</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1014.83</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>39.41</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>468.88</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>13.83</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>39.64</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1012.52</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>69.97</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>472.95</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>22.75</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>58.79</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1011.44</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>84.47</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>445.67</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>30.06</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>67.25</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1017.63</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>53.59</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>435.02</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>19.78</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>50.32</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1008.62</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>96.4</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>449.23</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>25.06</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>65.46</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1014.37</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>38.82</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>443.03</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>32.41</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>72.86</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1003.69</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>58.04</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>432.75</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>12.82</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>48.14</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1017.47</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>81.45</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>467.48</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>28.43</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>69.59</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1008.79</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>73.33</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>439.26</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>14.72</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>40.83</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.65</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>80.98</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>469.8</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>23.71</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>67.17</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1007.27</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>90.2</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>440.65</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>23.76</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>74.22</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.2</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>92.98</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>437.47</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>9.78</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>43.8</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1022.25</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>69.64</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>477.22</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>8.87</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>41.82</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1033.3</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>74.28</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>477.97</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>31.84</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>71.37</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1003.51</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>46.22</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>432.04</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>23.59</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>58.62</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1017.81</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>66.68</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>448.09</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>29.51</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>75.6</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1017.92</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>50.61</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>431.18</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>30.16</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>73.17</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1010.74</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>58.99</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>434.43</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>12.28</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>40.92</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1023.23</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>89.14</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>460.33</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>12.83</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>44.88</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1017.86</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>87.88</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>474.26</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>30.1</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>47.93</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1002.64</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>42.06</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>435.27</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>15.52</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>43.7</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1015.8</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>76.27</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>466.38</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>10.06</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>39.61</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1020.87</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>74.01</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>476.92</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>18.5</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>47.03</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1013.97</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>93.6</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>460.08</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>31.33</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>76.86</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>997.85</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>64.43</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>431.44</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>30.28</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>79.74</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1006.96</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>70.21</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>433.45</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>19.27</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>50.9</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1011.72</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>83.14</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>455.09</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>17.23</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>40.12</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1013.52</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>81.55</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>456.2</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>20.73</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>69.94</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.9</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>82.12</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>445.91</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>22.31</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>43.43</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1010.64</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>56.44</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>449.67</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>19.7</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>52.84</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1004.86</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>89.72</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>444.64</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>19.02</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>50.66</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1013.04</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>85.25</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>455.42</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>5.15</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>40.07</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1012.27</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>63.31</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>495.35</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>8.6</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>40.77</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1011.8</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>89.45</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>480.82</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>27.75</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>77.24</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1007.48</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>78.37</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>433.57</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>21.37</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>65.94</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1010.73</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>75.09</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>444.74</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>22.87</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>71.29</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1008.1</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>73.1</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>442.27</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>6.1</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>43.65</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1018.07</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>75.85</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>485.24</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>14.33</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>42.86</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1010.82</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>88.59</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>469.52</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>22.18</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>45.09</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1014.04</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>43.13</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>455.4</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>19.2</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>58.71</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.8</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>84.62</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>448.17</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>15.43</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>40.89</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1010.63</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>73.03</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>468.35</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>20.03</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>47.45</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.04</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>77.56</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>450.6</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>23.42</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>50.05</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1006.79</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>86.45</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>441.8</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>7.61</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>44.71</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1019.41</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>70.48</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>485.36</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>10.44</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>39.04</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1023.99</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>85.03</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>480.34</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>17.79</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>46.21</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1010.38</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>85.25</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>448.74</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>26.85</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>69.84</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1002.84</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>81.31</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>426.58</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>24.54</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>48.41</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1008.61</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>73.53</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>439.79</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>24.64</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>72.24</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1011.37</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>80.61</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>434.54</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>27.06</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>43.77</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1011.02</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>42.61</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>442.15</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>25.76</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>71.06</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1007.93</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>90.4</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>433.75</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>21.1</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>62.66</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1011.19</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>83.49</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>448.8</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>27.45</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>64.34</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1007.12</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>65.87</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>440.0</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>25.1</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>43.77</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1010.9</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>49.68</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>444.99</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>23.16</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>69.94</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1004.92</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>68.68</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>438.48</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>18.84</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>67.32</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1012.63</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>81.89</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>449.21</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>25.92</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>50.16</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1003.95</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>71.3</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>440.98</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "              <tr>\n",
       "                \n",
       "                \n",
       "                <td>28.75</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>64.84</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>1009.61</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>58.24</td>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td>441.3</td>\n",
       "                \n",
       "                \n",
       "              </tr>\n",
       "              \n",
       "            </tbody>\n",
       "          </table>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "  </div>\n",
       "</div><script class=\"pd_save is-viewer-good\">\n",
       "  $(function() {\n",
       "    var tableWrapper = $('.df-table-wrapper-0f542728');\n",
       "    var fixedHeader = $('.fixed-header', tableWrapper);\n",
       "    var tableContainer = $('.df-table-container', tableWrapper);\n",
       "    var table = $('.df-table', tableContainer);\n",
       "    var rows = $('tbody > tr', table);\n",
       "    var total = 47840;\n",
       "\n",
       "    fixedHeader\n",
       "      .css('width', table.width())\n",
       "      .find('.fixed-cell')\n",
       "      .each(function(i, e) {\n",
       "        $(this).css('width', $('.df-table-wrapper-0f542728 th:nth-child(' + (i+1) + ')').css('width'));\n",
       "      });\n",
       "\n",
       "    tableContainer.scroll(function() {\n",
       "      fixedHeader.css({ left: table.position().left });\n",
       "    });\n",
       "\n",
       "    rows.on(\"click\", function(e){\n",
       "        var txt = e.delegateTarget.innerText;\n",
       "        var splits = txt.split(\"\\t\");\n",
       "        var len = splits.length;\n",
       "        var hdrs = $(fixedHeader).find(\".fixed-cell\");\n",
       "        // Add all cells in the selected row as a map to be consumed by the target as needed\n",
       "        var payload = {type:\"select\", targetDivId: \"\" };\n",
       "        for (var i = 0; i < len; i++) {\n",
       "          payload[hdrs[i].innerHTML] = splits[i];\n",
       "        }\n",
       "\n",
       "        //simple selection highlighting, client adds \"selected\" class\n",
       "        $(this).addClass(\"selected\").siblings().removeClass(\"selected\");\n",
       "        $(document).trigger('pd_event', payload);\n",
       "    });\n",
       "\n",
       "    $('.df-table-search', tableWrapper).keyup(function() {\n",
       "      var val = '^(?=.*\\\\b' + $.trim($(this).val()).split(/\\s+/).join('\\\\b)(?=.*\\\\b') + ').*$';\n",
       "      var reg = RegExp(val, 'i');\n",
       "      var index = 0;\n",
       "      \n",
       "      rows.each(function(i, e) {\n",
       "        if (!reg.test($(this).text().replace(/\\s+/g, ' '))) {\n",
       "          $(this).attr('class', 'hidden');\n",
       "        }\n",
       "        else {\n",
       "          $(this).attr('class', (++index % 2 == 0 ? 'even' : 'odd'));\n",
       "        }\n",
       "      });\n",
       "\n",
       "      $('.df-table-search-count', tableWrapper).html('Showing ' + index + ' of ' + total);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  $(\".df-table-wrapper td:contains('http://')\").each(function(){var tc = this.textContent; $(this).wrapInner(\"<a target='_blank' href='\" + tc + \"'></a>\");});\n",
       "  $(\".df-table-wrapper td:contains('https://')\").each(function(){var tc = this.textContent; $(this).wrapInner(\"<a target='_blank' href='\" + tc + \"'></a>\");});\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(powerPlantDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, lets create a scatter plot to visualize the relationships between temperature and power output.\n",
    "\n",
    "First, select the type of the diagram, from the dropdown menu, as below:\n",
    "\n",
    "![Step 1](images/step1.jpeg)\n",
    "\n",
    "Then, follow the scatter plot option wizard, below. Drag and drop the columns Temperature (`AT`) and Power Output (`PE`) as keys and values to display. Select also how big your sample should be - 500 rows should be fine for now! \n",
    "\n",
    "\n",
    "![Step 2](images/step2.jpeg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "It looks like there is strong linear correlation between Temperature and Power\n",
    "Output.\n",
    "\n",
    "**ASIDE: A quick physics lesson**: This correlation is to be expected as the\n",
    "second law of thermodynamics puts a fundamental limit on the [thermal\n",
    "efficiency](https://en.wikipedia.org/wiki/Thermal_efficiency) of all heat-based\n",
    "engines. The limiting factors are:\n",
    "\n",
    " - The temperature at which the heat enters the engine ($T_{H}$)\n",
    " - The temperature of the environment into which the engine exhausts its waste\n",
    "heat ( $T_C$)\n",
    "\n",
    "Our temperature measurements are the temperature of the environment. From\n",
    "[Carnot's\n",
    "theorem](https://en.wikipedia.org/wiki/Carnot%27s_theorem_%28thermodynamics%29),\n",
    "no heat engine working between these two temperatures can exceed the Carnot\n",
    "Cycle efficiency:\n",
    "$n_{th} \\le 1 - \\frac{T_C}{T_H}$\n",
    "\n",
    "Note that as the environmental temperature increases, the efficiency decreases\n",
    "-- _this is the effect that we see in the above graph._\n",
    "\n",
    "### Exercise 4(b)\n",
    "\n",
    "Continue exploring the relationships (if any) between the variables and\n",
    "Power Output.\n",
    "For example, you could plot of Power(PE) as a function of Exhaust Vacuum\n",
    "(V), Pressure (AP) and  Humidity (RH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-431ba0ec2bb6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-431ba0ec2bb6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <Your code here>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<Your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Data Preparation\n",
    "\n",
    "The next step is to prepare the data for machine learning. Since all of this\n",
    "data is numeric and consistent this is a simple and straightforward task. In your group work this wont always be the case, so you need to clean up the data first!\n",
    "\n",
    "The goal is to use machine learning to determine a function that yields the\n",
    "output power as a function of a set of predictor features. Recall the ML process, below.\n",
    "\n",
    "![](images/Pipeline.jpg)\n",
    "\n",
    "The first step in building our ML pipeline is to convert the input data into a set of *features*. We will do this in Spark, using the   `VectorAssembler` for \n",
    "tranforming a set of DataFrame\n",
    "columns into a vector of features.\n",
    "\n",
    "\n",
    "The VectorAssembler is a transformer that combines a given list of columns into a single vector column. \n",
    "It is useful for combining raw features and features\n",
    "generated by different feature transformers into a single feature vector.\n",
    "VectorAssembler takes a list of input column names (each is a string) and the\n",
    "name of the output column (as a string).\n",
    "\n",
    "### Exercise 5(a)\n",
    "\n",
    "- Read the Spark documentation and usage examples for\n",
    "[VectorAssembler](https://spark.apache.org/docs/2.0.0/ml-features.html#vectorassembler), and convert the `powerPlantDF` to a DataFrame\n",
    "named `dataset`, so that:\n",
    "- Set the vectorizer's input columns to a list of the four columns of the input\n",
    "DataFrame: `[\"AT\", \"V\", \"AP\", \"RH\"]`\n",
    "- Set the vectorizer's output column name to `\"features\"`\n",
    "\n",
    "Yout code should look like:\n",
    "<pre>\n",
    "VectorAssembler(\n",
    "    inputCols=[\"AT\", \"V\", \"AP\", \"RH\"],\n",
    "    outputCol=\"features\")\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL_IN> with the appropriate code\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorizer = VectorAssembler(\n",
    "    inputCols = ['AT', 'V', 'AP', 'RH'],\n",
    "    outputCol = 'features')\n",
    "dataset = vectorizer.transform(powerPlantDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector assembler above, is not invasive. It transformed the powerPlantDF dataframe by appending a new column named features. Can you confirm this below, by observing the schema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AT: double (nullable = true)\n",
      " |-- V: double (nullable = true)\n",
      " |-- AP: double (nullable = true)\n",
      " |-- RH: double (nullable = true)\n",
      " |-- PE: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- AT: double (nullable = true)\n",
      " |-- V: double (nullable = true)\n",
      " |-- AP: double (nullable = true)\n",
      " |-- RH: double (nullable = true)\n",
      " |-- PE: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "powerPlantDF.printSchema()\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part 6: Data Preparation\n",
    "Now let's model our data to predict what the power output will be given a set of\n",
    "sensor readings\n",
    "\n",
    "Our first model will be based on simple linear regression since we saw some\n",
    "linear patterns in our data based on the scatter plots during the exploration\n",
    "stage.\n",
    "\n",
    "We need a way of evaluating how well our linear regression model predicts power\n",
    "output as a function of input parameters. We can do this by splitting up our\n",
    "initial data set into a _Training Set_ used to train our model and a _Test Set_\n",
    "used to evaluate the model's performance in giving predictions. We can use a\n",
    "DataFrame's [randomSplit()](https://spark.apache.org/docs/2.0.0/api/python/pyspa\n",
    "rk.sql.html#pyspark.sql.DataFrame.randomSplit) method to split our dataset. The\n",
    "method takes a list of weights and an optional random seed. The seed is used to\n",
    "initialize the random number generator used by the splitting function.\n",
    "\n",
    "### Exercise 6(a)\n",
    "\n",
    "Use the [randomSplit()](https://spark.apache.org/docs/1.6.2/api/python/pyspark.s\n",
    "ql.html#pyspark.sql.DataFrame.randomSplit) method to divide up `datasetDF` into\n",
    "a trainingSetDF (80% of the input DataFrame) and a testSetDF (20% of the input\n",
    "DataFrame), and for reproducibility, use the seed 1800009193. Then cache each\n",
    "DataFrame in memory to maximize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL_IN> with the appropriate code.\n",
    "# We'll hold out 20% of our data for testing and leave 80% for training\n",
    "seed = 1800009193\n",
    "(split20DF, split80DF) = dataset.randomSplit([.2, .8], seed)\n",
    "\n",
    "# Let's cache these datasets for performance\n",
    "testSetDF = split20DF\n",
    "trainingSetDF = split80DF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Linear Regression Model\n",
    "\n",
    "From the Wikipedia article on [Linear\n",
    "Regression](https://en.wikipedia.org/wiki/Linear_regression):\n",
    "> In statistics, linear regression is an approach for modeling the relationship\n",
    "between a scalar dependent variable \\\\( y \\\\) and one or more explanatory\n",
    "variables (or independent variables) denoted \\\\(X\\\\). In linear regression, the\n",
    "relationships are modeled using linear predictor functions whose unknown model\n",
    "parameters are estimated from the data. Such models are called linear models.\n",
    "\n",
    "Linear regression has many practical uses. Most applications fall into one of\n",
    "the following two broad categories:\n",
    "  - If the goal is prediction, or forecasting, or error reduction, linear\n",
    "regression can be used to fit a predictive model to an observed data set of\n",
    "\\\\(y\\\\) and \\\\(X\\\\) values. After developing such a model, if an additional\n",
    "value of \\\\(X\\\\) is then given without its accompanying value of \\\\(y\\\\), the\n",
    "fitted model can be used to make a prediction of the value of \\\\(y\\\\).\n",
    "  - Given a variable \\\\(y\\\\) and a number of variables \\\\( X_1 \\\\), ..., \\\\( X_p\n",
    "\\\\) that may be related to \\\\(y\\\\), linear regression analysis can be applied to\n",
    "quantify the strength of the relationship between \\\\(y\\\\) and the \\\\( X_j\\\\), to\n",
    "assess which \\\\( X_j \\\\) may have no relationship with \\\\(y\\\\) at all, and to\n",
    "identify which subsets of the \\\\( X_j \\\\) contain redundant information about\n",
    "\\\\(y\\\\).\n",
    "\n",
    "We are interested in both uses, as we would like to predict power output as a\n",
    "function of the input variables, and we would like to know which input variables\n",
    "are weakly or strongly correlated with power output.\n",
    "\n",
    "Since Linear Regression is simply a Line of best fit over the data that\n",
    "minimizes the square of the error, given multiple input dimensions we can\n",
    "express each predictor as a line function of the form:\n",
    "\n",
    "\\\\[ y = a + b x_1 + b x_2 + b x_i ... \\\\]\n",
    "\n",
    "where \\\\(a\\\\) is the intercept and the \\\\(b\\\\) are the coefficients.\n",
    "\n",
    "\n",
    "In Spark, a Linear regression model is another step in a ML pipeline. \n",
    "\n",
    "Run the cells below to create a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    " # Initialize the linear regression learner with default values for the parameters\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each learning algorithm, as the Linear Regression Model, has some parameters\n",
    "that affect how learning is done. This is custom for each learner.\n",
    "\n",
    "In the case of Linear Regression we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "featuresCol: features column name. (default: features)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0)\n",
      "solver: the solver algorithm for optimization. If this is not set or empty, default value is 'auto'. (default: auto)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    " # See which are the parameters\n",
    "print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two parameters are not optional:\n",
    "- The name of the label column to \"PE\" (i.e. which are the known values to\n",
    "learn)\n",
    "- The name of the prediction column to \"Predicted_PE\" (i.e. where the\n",
    "predictions values should be stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_4ea38e9478d6b0104f49"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.setPredictionCol(\"Predicted_PE\")\\\n",
    "  .setLabelCol(\"PE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also configure two parameters, which a re customary to the linear\n",
    "regression\n",
    "- the maximum number of iterations to 100\n",
    "- the regularization parameter to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_4ea38e9478d6b0104f49"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.setMaxIter(100)\\\n",
    "  .setRegParam(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 Create a pipeline\n",
    "\n",
    "Next, to create a workflow that puts together the vectorization and the Linear\n",
    "Regression learner, we can create an ML Pipeline that stitch together the two\n",
    "trasnformations we created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_4ef897cbbd9dcad81aff"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrPipeline = Pipeline()\n",
    "lrPipeline.setStages([vectorizer, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8 (a) Train with the training dataset the model\n",
    "\n",
    "Next, we create a Linear Regression model that has been trained (or *fit*) with\n",
    "the training data set.\n",
    "To do so we apply the `lrPipeline` pipeline of the training dataset, i.e. first\n",
    "vectorize and then train with the linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Output column features already exists.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o53.transform.\n: java.lang.IllegalArgumentException: Output column features already exists.\n\tat org.apache.spark.ml.feature.VectorAssembler.transformSchema(VectorAssembler.scala:124)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:54)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-cbdf2549c20b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's first train on the trqining dataset to see what we get\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlrModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingSetDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Output column features already exists.'"
     ]
    }
   ],
   "source": [
    " # Let's first train on the trqining dataset to see what we get\n",
    "lrModel = lrPipeline.fit(trainingSetDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8 (b) Inspect the model\n",
    "The learner has been trained now. Lets inspect which are the wrights for the\n",
    "(trained) linear regression model, which is now stored as the second element of\n",
    "our pipeline.\n",
    "\n",
    "Run the next cell. Ensure that you understand what's going on. Ask for help if\n",
    "you have questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients (i.e., weights) are as follows:\n",
    "weights = lrModel.stages[1].coefficients\n",
    "\n",
    "# The corresponding features for these weights are:\n",
    "featuresNoLabel = vectorizer.getInputCols()\n",
    "\n",
    "\n",
    "# Print coefficients \n",
    "list(zip(featuresNoLabel, weights))\n",
    " \n",
    " # Print the intercept\n",
    "print(lrModel.stages[1].intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**\n",
    "\n",
    "- Write down the linear regression equation that your model learned.\n",
    "- Recall when we visualized each predictor against Power Output using a Scatter\n",
    "Plot,\n",
    "does the final equation seems logical given\n",
    "those visualizations?\n",
    "\n",
    "## Part 9: Learner evaluation\n",
    "\n",
    "### Exercise 9(a) Apply the learner to make predictions\n",
    "\n",
    "Now let's see what our predictions look like given this model. We apply our\n",
    "Linear Regression model to the 20% of the data that we split from the input\n",
    "dataset. The output of the model will be a predicted Power Output column named\n",
    "\"Predicted_PE\".\n",
    "\n",
    "- Run the next cell\n",
    "- Scroll through the resulting table and notice how the values in the Power\n",
    "Output (PE) column compare to the corresponding values in the predicted Power\n",
    "Output (Predicted_PE) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Apply our LR model to the test data and predict power output\n",
    "predictionsLR = lrModel.transform(testSetDF).select(\"AT\", \"V\", \"AP\", \"RH\", \"PE\", \"Predicted_PE\")\n",
    "\n",
    " # Print the first 15 rows of your predictions\n",
    "predictionsLR.show(15) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a visual inspection of the predictions, we can see that they are close to\n",
    "the actual values.\n",
    "\n",
    "\n",
    "However, we would like a scientific measure of how well the Linear Regression\n",
    "model is performing in accurately predicting values. To perform this\n",
    "measurement, we can use an evaluation metric such as [Root Mean Squared\n",
    "Error](https://en.wikipedia.org/wiki/Root-mean-square_deviation) (RMSE) to\n",
    "validate our Linear Regression model.\n",
    "\n",
    "RSME is defined as follows: \\\\( RMSE = \\sqrt{\\frac{\\sum_{i = 1}^{n} (x_i -\n",
    "y_i)^2}{n}}\\\\) where \\\\(y_i\\\\) is the observed value and \\\\(x_i\\\\) is the\n",
    "predicted value\n",
    "\n",
    "RMSE is a frequently used measure of the differences between values predicted by\n",
    "a model or an estimator and the values actually observed. The lower the RMSE,\n",
    "the better our model.\n",
    "\n",
    "Spark ML Pipeline provides several regression analysis metrics, including [RegressionEvaluator](https://spark.apache.org/docs/2.0.0/api/python/pyspark.ml.html#pyspark.ml.evaluation.RegressionEvaluator).\n",
    "\n",
    "After we create an instance of [RegressionEvaluator](https://spark.apache.org/do\n",
    "cs/2.0.0/api/python/pyspark.ml.html#pyspark.ml.evaluation.RegressionEvaluator),\n",
    "we set the label column name to \"PE\" and set the prediction column name to\n",
    "\"Predicted_PE\". We then invoke the evaluator on the predictions.\n",
    "\n",
    "### Exercise 9 (b) Model evaluation with RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Now let's compute an evaluation metric for our test dataset\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    " # Create an RMSE evaluator using the label and predicted columns\n",
    "regEval = RegressionEvaluator(predictionCol=\"Predicted_PE\", labelCol=\"PE\", metricName=\"rmse\")\n",
    "\n",
    " # Run the evaluator on the DataFrame\n",
    "rmse = regEval.evaluate(predictionsLR)\n",
    "\n",
    "print(\"Root Mean Squared Error: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9(c) Model evaluation with r^2\n",
    "\n",
    "Another useful statistical evaluation metric is the coefficient of\n",
    "determination, denoted \\\\(R^2\\\\) or \\\\(r^2\\\\) and pronounced \"R squared\". It is\n",
    "a number that indicates the proportion of the variance in the dependent variable\n",
    "that is predictable from the independent variable and it provides a measure of\n",
    "how well observed outcomes are replicated by the model, based on the proportion\n",
    "of total variation of outcomes explained by the model. The coefficient of\n",
    "determination ranges from 0 to 1 (closer to 1), and the higher the value, the\n",
    "better our model.\n",
    "\n",
    "To compute \\\\(r^2\\\\), we invoke the evaluator with  `regEval.metricName: \"r2\"`\n",
    "\n",
    "\n",
    "Run the next cell and ensure that you understand what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Now let's compute another evaluation metric for our test dataset\n",
    "r2 = regEval.evaluate(predictionsLR, {regEval.metricName: \"r2\"})\n",
    "\n",
    "print(\"r2: {0:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Parameter Tuning and Evaluation\n",
    "\n",
    "Now that we have a model with all of the data let's try to make a better model\n",
    "by tuning over several parameters. The process of tuning a model is known as\n",
    "[Model Selection](https://spark.apache.org/docs/2.0.0/api/python/pyspark.ml.html#module-pyspark.ml.tuning) or [Hyperparameter\n",
    "Tuning](https://spark.apache.org/docs/2.0.0/api/python/pyspark.ml.html#module-\n",
    "pyspark.ml.tuning), and Spark ML Pipeline makes the tuning process very simple\n",
    "and easy.\n",
    "\n",
    "An important task in ML is model selection, or using data to find the best model\n",
    "or parameters for a given task. This is also called tuning. Tuning may be done\n",
    "for individual Estimators such as\n",
    "[LinearRegression](https://spark.apache.org/docs/1.6.2/ml-classification-\n",
    "regression.html#linear-regression), or for entire Pipelines which include\n",
    "multiple algorithms, featurization, and other steps. Users can tune an entire\n",
    "Pipeline at once, rather than tuning each element in the Pipeline separately.\n",
    "\n",
    "Spark ML Pipeline supports model selection using tools such as [CrossValidator](\n",
    "https://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.tuning\n",
    ".CrossValidator), which requires the following items:\n",
    "\n",
    "  - [Estimator](https://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#p\n",
    "yspark.ml.Estimator): algorithm or Pipeline to tune\n",
    "  - [Set of ParamMaps](https://spark.apache.org/docs/1.6.2/api/python/pyspark.ml\n",
    ".html#pyspark.ml.tuning.ParamGridBuilder): parameters to choose from, sometimes\n",
    "called a _parameter grid_ to search over\n",
    "  - [Evaluator](https://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#p\n",
    "yspark.ml.evaluation.Evaluator): metric to measure how well a fitted Model does\n",
    "on held-out test data\n",
    "\n",
    "At a high level, model selection tools such as CrossValidator\n",
    "work as follows:\n",
    "\n",
    "  - They split the input data into separate training and test datasets.\n",
    "  - For each (training, test) pair, they iterate through the set of ParamMaps:\n",
    "    - For each ParamMap, they fit the Estimator\n",
    "using those parameters, get the fitted Model, and evaluate the Model's\n",
    "performance using the Evaluator.\n",
    "  - They select the Model produced by the best-performing set of parameters.\n",
    "\n",
    "The Evaluator can be a [RegressionEvaluator](https://spark.apache.org/docs/1.6.2\n",
    "/api/python/pyspark.ml.html#pyspark.ml.evaluation.RegressionEvaluator) for\n",
    "regression problems. To help construct the parameter grid, users\n",
    "can use the [ParamGridBuilder](https://spark.apache.org/docs/1.6.2/api/python/py\n",
    "spark.ml.html#pyspark.ml.tuning.ParamGridBuilder) utility.\n",
    "\n",
    "Note that cross-validation over a grid of parameters is expensive. For example,\n",
    "in the next cell, the parameter grid has 10 values for\n",
    "[lr.regParam](https://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pys\n",
    "park.ml.regression.LinearRegression.regParam), and CrossValidator uses 3 folds.\n",
    "This\n",
    "multiplies out to (10 x 3) = 30 different models being trained. In realistic\n",
    "settings, it can be common to try many more parameters (e.g., multiple values\n",
    "for multiple parameters) and use more folds (_k_ = 3 and _k_ = 10 are common).\n",
    "In other words, using CrossValidator can be very expensive.\n",
    "However, it is also a well-established method for choosing parameters which is\n",
    "more statistically sound than heuristic hand-tuning.\n",
    "\n",
    "\n",
    "### Exercise 10 (a)\n",
    "We perform the following steps:\n",
    "\n",
    "  - Create a CrossValidator using the Pipeline and RegressionEvaluator that we\n",
    "created earlier, and set the\n",
    "number of folds to 3\n",
    "  - Create a list of 10 regularization parameters\n",
    "  - Use ParamGridBuilder to build a parameter grid with the\n",
    "regularization parameters and add the grid to the CrossValidator\n",
    "  - Run the CrossValidator to find the parameters that yield\n",
    "the best model (i.e., lowest RMSE) and return the best model.\n",
    "\n",
    "\n",
    "Run the next cell. _Note that it will take some time to run the CrossValidator\n",
    "as it will run almost 200 Spark jobs!_\n",
    "\n",
    "Expand the Spark Job Monitor, to visualize what is going on in the background!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    " # We can reuse the RegressionEvaluator, regEval, to judge the model based on the best Root Mean Squared Error\n",
    " # Let's create our CrossValidator with 3 fold cross validation\n",
    "crossval = CrossValidator(estimator=lrPipeline, evaluator=regEval, numFolds=3)\n",
    "\n",
    " # Let's tune over our regularization parameter from 0.01 to 0.10\n",
    "regParam = [x / 100.0 for x in range(1, 11)]\n",
    "\n",
    " # We'll create a paramter grid using the ParamGridBuilder, and add the grid to the CrossValidator\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, regParam)\n",
    "             .build())\n",
    "crossval.setEstimatorParamMaps(paramGrid)\n",
    "\n",
    " # Now let's find and return the best model\n",
    "cvModel = crossval.fit(trainingSetDF).bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10 (b)\n",
    "\n",
    "Now that we have tuned our Linear Regression model, let's see what the new RMSE\n",
    "and \\\\(r^2\\\\) values are for these models, and compare with our initial model.\n",
    "\n",
    "\n",
    "Complete and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL_IN> with the appropriate code.\n",
    "# Now let's use cvModel to compute an evaluation metric for our test dataset: testSetDF\n",
    "predictionsRL = <FILL_IN>\n",
    "\n",
    "# Run the previously created RMSE evaluator, regEval, on the predictionsAndLabelsDF DataFrame\n",
    "rmseLR = <FILL_IN>\n",
    "\n",
    "# Now let's compute the r2 evaluation metric for our test dataset\n",
    "r2LR = <FILL_IN>\n",
    "\n",
    "print(\"Original Root Mean Squared Error: {0:2.2f}\".format(rmse))\n",
    "print(\"New Root Mean Squared Error: {0:2.2f}\".format(rmseLR))\n",
    "print(\"Old r2: {0:2.2f}\".format(r2))\n",
    "print(\"New r2: {0:2.2f}\".format(r2LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**  \n",
    "How does the initially untuned model compare with the tuned model?\n",
    "Are they statistically similar?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
